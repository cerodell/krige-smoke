{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9689fb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Universal Kriging (UK)\n",
    "Universal Kriging (UK) is a variant of the Ordinary Kriging under non-stationary condition where mean differ in a deterministic way in different locations (local trend or drift), while only the variance is constant. This second-order stationarity (“weak stationarity”) is often a pertinent assumption with environmental exposures. In UK, usually first trend is calculated as a function of the coordinates and then the variation in what is left over (the residuals) as a random field is added to trend for making final prediction.\n",
    "\n",
    "$$\n",
    "\\begin{aligned} Z\\left(s_{i}\\right) &=m\\left(s_{i}\\right)+e\\left(s_{i}\\right) \\\\ Z(\\vec{x}) &=\\sum_{k=0}^{K} \\beta_{k} f_{k}(\\vec{x})+\\varepsilon(\\vec{x}) \\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "- Where the $f_{k}$ are some global functions of position  $\\vec{x}$  and the  $\\beta_{k}$ are the coefficients.\n",
    "\n",
    "- The $f$ are called base functions. The  $\\varepsilon(\\vec{x})$  is the spatially-correlated error, which is modelled as before, with a variogram, but now only considering the residuals, after the global trend is removed.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "\n",
    "The definition above come from a [geospatial data science course](https://zia207.github.io/geospatial-r-github.io/index.html) created by [Prof. Zia Ahmed](https://www.buffalo.edu/renew/about-us/leadership/zia-ahmed.html) at The State of New York University at Buffalo.\n",
    " \n",
    "- Thanks Prof. Zia Ahmed for the great resource!  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79487df",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Load python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48021f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import context\n",
    "import salem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from pykrige.uk import UniversalKriging\n",
    "\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.utils import pixel2poly, plotvariogram, cfcompliant\n",
    "from context import data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bd156",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Load Data\n",
    "Open the reformated data with the linear, meter-based Lambert projection (EPSG:3347).\n",
    "- Again this is helpful as lat/lon coordinates are less suitable for measuring distances which is important for spatial interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1544ff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(str(data_dir) + \"/obs/gpm25.csv\")\n",
    "gpm25 = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    crs=\"EPSG:4326\",\n",
    "    geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]),\n",
    ").to_crs(\"EPSG:3347\")\n",
    "gpm25[\"Easting\"], gpm25[\"Northing\"] = gpm25.geometry.x, gpm25.geometry.y\n",
    "gpm25.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891d35a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Create Grid\n",
    "Again we will create a grid that we want to use for the interpolation.\n",
    "\n",
    "- The grid in the fromate of a dataset is helpful for reprojecting our covariates to match the interpolated grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74bed5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## define the desired  grid resolution in meters\n",
    "resolution = 20_000  # grid cell size in meters\n",
    "\n",
    "## make grid based on dataset bounds and resolution\n",
    "gridx = np.arange(\n",
    "    gpm25.bounds.minx.min() - resolution,\n",
    "    gpm25.bounds.maxx.max() + resolution,\n",
    "    resolution,\n",
    ")\n",
    "gridy = np.arange(\n",
    "    gpm25.bounds.miny.min() - resolution,\n",
    "    gpm25.bounds.maxy.max() + resolution,\n",
    "    resolution,\n",
    ")\n",
    "\n",
    "## use salem to create a dataset with the grid.\n",
    "krig_ds = salem.Grid(\n",
    "    nxny=(len(gridx), len(gridy)),\n",
    "    dxdy=(resolution, resolution),\n",
    "    x0y0=(gpm25.bounds.minx.min(), gpm25.bounds.miny.min()),\n",
    "    proj=\"epsg:3347\",\n",
    "    pixel_ref=\"corner\",\n",
    ").to_dataset()\n",
    "## print dataset\n",
    "krig_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9d6aa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Covariate\n",
    "We will use the Bluesky Canada Smoke Forecast (BlueSky) as a covariate for universal kriging with specified drift. The data comes from [firesmoke.ca](https://firesmoke.ca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3367f0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "ds = salem.open_xr_dataset(str(data_dir) + f\"/dispersion1.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9aee36",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Set up specified drift\n",
    "For specified we need the modeled derived PM2.5 concentration from BlueSky at every aq monitor location and BleuSky modeled PM2.5 concentration on the same grid we are interpolating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ce308",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### BlueSky modeled PM2.5 concentration at AQs location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13e070",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "y = xr.DataArray(\n",
    "    np.array(df[\"lat\"]),\n",
    "    dims=\"ids\",\n",
    "    coords=dict(ids=df.id.values),\n",
    ")\n",
    "x = xr.DataArray(\n",
    "    np.array(df[\"lon\"]),\n",
    "    dims=\"ids\",\n",
    "    coords=dict(ids=df.id.values),\n",
    ")\n",
    "var_points = ds[\"pm25\"].interp(x=x, y=y, method=\"linear\")\n",
    "# print(var_points)\n",
    "if len(df.index) == len(var_points.values):\n",
    "    var_points = var_points.values\n",
    "else:\n",
    "    raise ValueError(\"Lengths dont match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6794ec",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### BlueSky PM2.5 Data on grid\n",
    "Now we will transform the BlueSky PM2.5 data to be on the grid we are interpolating too. This is feed in as a specified drift array when executing the interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40553867",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_T = krig_ds.salem.transform(ds)\n",
    "var_array = ds_T[\"pm25\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81a066",
   "metadata": {},
   "source": [
    "#### Plot BlueSky PM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9d7e0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.Orthographic(-80, 35))\n",
    "ax.set_global()\n",
    "ds[\"pm25\"].plot(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    levels=[0, 5, 10, 20, 40, 80, 160, 300, 600],\n",
    "    cmap=\"Reds\",\n",
    ")\n",
    "ax.coastlines()\n",
    "ax.set_extent([-132, -85, 35, 65], crs=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c048eec",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "##  Setup UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cce998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlags = 15\n",
    "# variogram_model = \"spherical\"\n",
    "\n",
    "\n",
    "# startTime = datetime.now()\n",
    "# krig = UniversalKriging(\n",
    "#     x=gpm25[\"Easting\"],  ## x location of aq monitors in lambert conformal\n",
    "#     y=gpm25[\"Northing\"],  ## y location of aq monitors in lambert conformal\n",
    "#     z=gpm25[\"PM2.5\"],  ## measured PM 2.5 concentrations at locations\n",
    "#     drift_terms=[\"specified\"],\n",
    "#     variogram_model=variogram_model,\n",
    "#     nlags=nlags,\n",
    "#     specified_drift=[var_points],  ## BlueSky PM2.5 at aq monitors\n",
    "# )\n",
    "# print(f\"UK build time {datetime.now() - startTime}\")\n",
    "\n",
    "# # %% [markdown]\n",
    "# # #### Our variogram parameters\n",
    "# # PyKrige will optimize most parameters based on user defined empirical model and the number of bins.\n",
    "# #\n",
    "# # - I tested several empirical models and bin sizes and found (for this case study) that a spherical model with 15 bins was optimal based on the output statics.\n",
    "# #\n",
    "# #  - The literature supports spherical for geospatial interpolation applications over other methods.\n",
    "# # %%\n",
    "# plotvariogram(krig)\n",
    "\n",
    "\n",
    "# # %% [markdown]\n",
    "# # ### Execute UK\n",
    "# # Interpolate data to our grid using UK with specified drift. Where the specified drift is the linear correlation of BlueSky PM2.5 to PM2.5 at all locations and on the interploated grid for kriging.\n",
    "# # %%\n",
    "# var_array[var_array > np.max(var_points)] = np.max(var_points) + 20\n",
    "\n",
    "# startTime = datetime.now()\n",
    "# z, ss = krig.execute(\"grid\", gridx, gridy, specified_drift_arrays=[var_array])\n",
    "# print(f\"UK execution time {datetime.now() - startTime}\")\n",
    "# UK_pm25 = np.where(z < 0, 0, z)\n",
    "\n",
    "# krig_ds[\"UK_pm25\"] = ((\"y\", \"x\"), UK_pm25)\n",
    "\n",
    "# # %% [markdown]\n",
    "# # ### Plot UK\n",
    "# # Convert data to polygons to be plot-able on a slippy mapbox. This is not necessary but but :)\n",
    "\n",
    "# # %%\n",
    "# polygons, values = pixel2poly(gridx, gridy, UK_pm25, resolution)\n",
    "# pm25_model = gpd.GeoDataFrame(\n",
    "#     {\"Modelled PM2.5\": values}, geometry=polygons, crs=\"EPSG:3347\"\n",
    "# ).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# fig = px.choropleth_mapbox(\n",
    "#     pm25_model,\n",
    "#     geojson=pm25_model.geometry,\n",
    "#     locations=pm25_model.index,\n",
    "#     color=\"Modelled PM2.5\",\n",
    "#     color_continuous_scale=\"jet\",\n",
    "#     center={\"lat\": 50.0, \"lon\": -110.0},\n",
    "#     zoom=2.5,\n",
    "#     mapbox_style=\"carto-positron\",\n",
    "#     opacity=0.6,\n",
    "# )\n",
    "# fig.update_layout(margin=dict(l=0, r=0, t=30, b=10))\n",
    "# fig.update_traces(marker_line_width=0)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
